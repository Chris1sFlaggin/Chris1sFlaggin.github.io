üìò Capitolo 1: Introduzione e Strutture del Sistema (Domande 1-20)  
 * Qual √® la definizione formale di Sistema Operativo fornita dal testo?  
   * Risposta: √à un programma che agisce da intermediario tra l'utente e l'hardware, gestendo le risorse e fornendo un ambiente per l'esecuzione dei programmi in modo efficiente e sicuro.  
 * Perch√© il Sistema Operativo √® definito "Allocatore di Risorse"?  
   * Risposta: Perch√© deve gestire e assegnare in modo equo e senza conflitti le risorse limitate del computer (CPU, memoria, spazio su disco, dispositivi I/O) tra i vari programmi e utenti.  
 * Cos'√® il "Kernel" e in cosa differisce dai programmi di sistema?  
   * Risposta: Il kernel √® l'unico programma sempre in esecuzione sul computer. I programmi di sistema sono software associati al SO ma non fanno parte del core, mentre i programmi applicativi sono quelli dell'utente.  
 * Descrivi il meccanismo di Interrupt (Interruzione).  
   * Risposta: √à un segnale inviato dall'hardware o dal software alla CPU per segnalare un evento che richiede attenzione immediata. La CPU sospende il lavoro corrente e trasferisce l'esecuzione a una routine di servizio (Interrupt Service Routine).  
 * Cos'√® il Vettore delle Interruzioni (Interrupt Vector)?  
   * Risposta: √à una tabella di indirizzi di memoria che punta alle varie routine di gestione delle interruzioni, permettendo alla CPU di saltare rapidamente alla funzione corretta in base al tipo di segnale ricevuto.  
 * Spiega la differenza tra I/O sincrono e asincrono.  
   * Risposta: Nell'I/O sincrono il controllo torna all'utente solo al termine dell'operazione. In quello asincrono, il controllo torna immediatamente e il programma pu√≤ fare altro mentre l'I/O prosegue.  
 * Cos'√® l'accesso diretto alla memoria (DMA - Direct Memory Access)?  
   * Risposta: √à una tecnica che permette a un dispositivo di I/O ad alta velocit√† di trasferire interi blocchi di dati direttamente da/verso la memoria principale senza l'intervento costante della CPU per ogni byte.  
 * Descrivi la gerarchia della memoria in base a velocit√†, costo e volatilit√†.  
   * Risposta: La gerarchia va dai Registri (pi√π veloci/cari/piccoli) alla Cache, RAM, Disco a stato solido (SSD), Disco Rigido (HDD) e Nastri (pi√π lenti/economici/grandi).  
       
 * Cos'√® il Caching e perch√© √® fondamentale?  
   * Risposta: √à la copia di informazioni in una memoria pi√π veloce (cache) per un accesso rapido. √à fondamentale per mitigare il divario di velocit√† tra i componenti (es. tra CPU e RAM).  
 * Definisci il Multiprogramming (Multiprogrammazione).  
   * Risposta: √à la capacit√† di tenere pi√π processi in memoria contemporaneamente affinch√© la CPU abbia sempre un lavoro da eseguire, aumentando cos√¨ l'utilizzo della CPU (CPU utilization).  
 * Cos'√® il Time-Sharing (Smultitasking) e come si differenzia dalla multiprogrammazione?  
   * Risposta: √à un'estensione logica della multiprogrammazione in cui la CPU commuta tra i processi cos√¨ velocemente che gli utenti possono interagire con ogni programma durante l'esecuzione.  
 * Spiega il funzionamento del Dual-Mode (User mode vs Kernel mode).  
   * Risposta: L'hardware fornisce un bit di modalit√† (mode bit). In User Mode (1) l'accesso √® limitato; in Kernel Mode (0) il SO ha il controllo totale. Serve a proteggere il sistema da utenti malintenzionati o errori.  
 * Cos'√® una "Istruzione Privilegiata"?  
   * Risposta: Un'istruzione che pu√≤ essere eseguita solo in Kernel Mode (es. disabilitare interruzioni, gestire la memoria, accedere all'I/O). Se eseguita in User Mode, causa un Trap.  
 * Cos'√® il Program Counter (PC)?  
   * Risposta: Un registro che contiene l'indirizzo della prossima istruzione da eseguire per un determinato processo.  
 * Qual √® la differenza tra un sistema monoprocessore e uno multiprocessore (Symmetric Multiprocessing - SMP)?  
   * Risposta: Nel monoprocessore c'√® una sola CPU. Nell'SMP, pi√π processori condividono la stessa memoria fisica e il sistema operativo, eseguendo compiti in parallelo.  
 * Cos'√® un sistema Clustered?  
   * Risposta: Un insieme di sistemi separati (nodi) collegati tra loro che lavorano insieme, spesso condividendo lo storage, per fornire alta affidabilit√† e prestazioni.  
 * A cosa serve il Timer di sistema?  
   * Risposta: Serve a impedire che un programma utente monopolizzi la CPU. Alla scadenza del timer, viene generata un'interruzione che restituisce il controllo al SO.  
 * Cosa si intende per "Gestione della Memoria" nel Capitolo 1?  
   * Risposta: Il SO deve tracciare quali parti della memoria sono in uso, decidere quali processi caricare quando lo spazio √® disponibile e allocare/deallocare spazio secondo necessit√†.  
 * Cos'√® la Protezione e la Sicurezza (Protection vs Security)?  
   * Risposta: La protezione √® il meccanismo per controllare l'accesso alle risorse interne; la sicurezza √® la difesa del sistema contro attacchi esterni (virus, hacker).  
 * Definisci il concetto di "Sistema Operativo Real-Time".  
   * Risposta: Un sistema con vincoli temporali rigidi dove l'elaborazione deve essere completata entro scadenze precise (deadline), pena il fallimento del sistema.  
  
üìò Capitolo 2: Strutture del Sistema (Domande 21-40)  
21. Cosa sono le System Call e come vengono utilizzate da un programma?  
 * Risposta: Sono l'interfaccia di programmazione tra un processo e il sistema operativo. Generalmente non vengono chiamate direttamente, ma tramite API (Application Programming Interface) come POSIX (Linux) o Win32 (Windows).  
22. Descrivi il meccanismo di passaggio dei parametri alle System Call.  
 * Risposta: Esistono tre metodi: 1) Tramite registri della CPU (veloce ma limitato); 2) Tramite un blocco o tabella in memoria, il cui indirizzo √® passato in un registro; 3) Tramite lo stack (pila), dove i parametri vengono inseriti (pushed) dal programma e prelevati dal SO.  
23. Qual √® la differenza tra Programmi di Sistema (System Programs) e System Call?  
 * Risposta: Le System Call sono funzioni di base del kernel. I Programmi di Sistema sono utility fornite con il SO (es. ls, cp, editor di testo) che utilizzano le system call per offrire un ambiente di sviluppo ed esecuzione all'utente.  
24. Elenca le 5 categorie principali di System Call.  
 * Risposta: 1) Controllo dei processi; 2) Manipolazione dei file; 3) Gestione dei dispositivi (I/O); 4) Mantenimento delle informazioni; 5) Comunicazioni.  
25. Cos'√® l'interprete dei comandi (Shell) e dove risiede?  
 * Risposta: √à un programma di sistema che legge e interpreta i comandi impartiti dall'utente. Pu√≤ essere integrato nel kernel (raro) o essere un programma separato che viene avviato al login.  
26. Descrivi la struttura a Monolite (Monolithic Kernel).  
 * Risposta: Tutto il sistema operativo (scheduling, file system, gestione memoria) risiede in un unico grande spazio di indirizzamento nel kernel. √à molto veloce per via dell'overhead ridotto, ma difficile da manutenere ed estendere.  
27. Cos'√® la struttura a Strati (Layered Approach)?  
 * Risposta: Il SO √® diviso in livelli. Il livello 0 √® l'hardware, l'ultimo √® l'interfaccia utente. Ogni livello usa solo i servizi del livello inferiore. √à facile da debuggare ma difficile da progettare efficientemente.  
28. Spiega la filosofia del Microkernel.  
 * Risposta: Sposta il maggior numero possibile di servizi dal kernel allo "spazio utente" (user space). Il kernel gestisce solo la comunicazione minima, la memoria e lo scheduling. √à molto sicuro e facile da estendere.  
29. Come comunicano i moduli in un sistema a Microkernel?  
 * Risposta: Tramite il Message Passing (scambio di messaggi). Se un programma vuole leggere un file, invia un messaggio al servizio file system attraverso il microkernel.  
30. Cosa sono i Moduli Caricabili (Loadable Kernel Modules - LKM)?  
 * Risposta: √à l'approccio moderno (usato da Linux). Il kernel ha un core centrale e pu√≤ caricare o scaricare moduli (es. driver, file system) a tempo di esecuzione senza dover riavviare il sistema.  
31. Cos'√® un Sistema Ibrido?  
 * Risposta: Un sistema che combina diverse architetture per bilanciare prestazioni e modularit√† (es. macOS usa un mix di microkernel Mach e componenti monolitici BSD).  
32. A cosa serve il "System Boot" (Avvio del sistema)?  
 * Risposta: √à il processo di caricamento del kernel in memoria. Inizia con un piccolo codice chiamato bootstrap program (nella ROM o EEPROM) che individua il kernel sul disco, lo carica e lo avvia.  
33. Qual √® il ruolo dei Servizi del Sistema Operativo?  
 * Risposta: Fornire funzioni comuni agli utenti: esecuzione programmi, operazioni di I/O, manipolazione del file system, comunicazioni, rilevamento errori, allocazione risorse e protezione.  
34. Cos'√® l'interfaccia GUI rispetto alla CLI?  
 * Risposta: La CLI (Command Line Interface) usa testo e tastiera; la GUI (Graphical User Interface) usa icone, finestre e dispositivi di puntamento. Entrambe servono a invocare i servizi del SO.  
35. Come viene gestito l'errore di una System Call?  
 * Risposta: Solitamente la chiamata restituisce un codice d'errore (es. -1) e scrive il dettaglio in una variabile globale (es. errno in C).  
36. Perch√© le API sono preferite alle System Call dirette?  
 * Risposta: Per la portabilit√†. Un programma scritto usando le API pu√≤ essere compilato su diversi sistemi che supportano quell'interfaccia, senza conoscere i dettagli specifici del kernel sottostante.  
37. Cos'√® la "System Call Interface"?  
 * Risposta: √à lo strato che intercetta le chiamate alle API e invoca le corrispondenti funzioni nel kernel, gestendo una tabella di numeri identificativi per ogni system call.  
38. Qual √® il vantaggio principale del Microkernel rispetto al Monolito?  
 * Risposta: La robustezza: se un servizio (es. il driver della stampante) crasha in spazio utente, il kernel continua a funzionare. Nel monolito, un errore in un driver pu√≤ bloccare l'intero sistema.  
39. Cos'√® il "Core Dump"?  
 * Risposta: Un file generato dal SO quando un processo fallisce, contenente lo stato della memoria del processo in quel momento per scopi di debugging.  
40. Qual √® l'obiettivo principale dei sistemi Virtual Machine?  
 * Risposta: Emulare l'hardware di una macchina fisica per permettere l'esecuzione di pi√π sistemi operativi contemporaneamente in modo isolato sullo stesso hardware.  
  
üìò Capitolo 3: Processi (Domande 41-60)  
41. Qual √® la differenza formale tra Programma e Processo?  
 * Risposta: Il programma √® un'entit√† passiva (un file eseguibile su disco); il processo √® un'entit√† attiva, un programma in esecuzione che include il Program Counter, i registri della CPU e lo stack.  
42. Descrivi le sezioni di un processo in memoria (Stack, Heap, Data, Text).  
 * Risposta: 1) Text: il codice eseguibile; 2) Data: variabili globali e statiche; 3) Heap: memoria allocata dinamicamente durante il run-time; 4) Stack: dati temporanei (parametri di funzioni, indirizzi di ritorno, variabili locali).  
43. Quali sono i 5 stati principali di un processo?  
 * Risposta: 1) New (creazione); 2) Running (istruzioni in esecuzione); 3) Waiting (in attesa di un evento/IO); 4) Ready (pronto per essere assegnato alla CPU); 5) Terminated (fine esecuzione).  
44. Cos'√® il Process Control Block (PCB)?  
 * Risposta: √à la struttura dati nel kernel che contiene tutte le informazioni di un processo: stato, PC, registri, limiti di memoria, elenco dei file aperti e statistiche di scheduling.  
45. Cos'√® il Context Switch (Cambio di contesto) e perch√© √® considerato un costo (overhead)?  
 * Risposta: √à il salvataggio dello stato del processo attuale e il caricamento di quello del nuovo processo. √à un costo perch√© la CPU non compie lavoro utile per l'utente durante questa operazione.  
46. Spiega la differenza tra lo Scheduler a breve termine (CPU Scheduler) e a lungo termine (Job Scheduler).  
 * Risposta: Quello a breve termine sceglie quale processo eseguire tra quelli pronti (frequente); quello a lungo termine controlla il grado di multiprogrammazione decidendo quali processi portare dal disco alla memoria (meno frequente).  
47. Cos'√® un processo "I/O-bound" rispetto a uno "CPU-bound"?  
 * Risposta: Un processo I/O-bound passa pi√π tempo a fare I/O che calcoli (brevi raffiche di CPU); un processo CPU-bound usa la maggior parte del tempo per calcoli (lunghe raffiche di CPU).  
48. Descrivi il meccanismo di creazione dei processi: fork() e exec().  
 * Risposta: fork() crea un processo figlio che √® una copia esatta del padre; exec() sostituisce lo spazio di memoria del processo con un nuovo programma.  
49. Cosa succede se un padre termina prima del figlio?  
 * Risposta: Il figlio diventa un processo Orfano (Orphan) e viene solitamente "adottato" dal processo radice (init o systemd).  
50. Cos'√® un processo "Zombie"?  
 * Risposta: Un processo che √® terminato ma la cui voce nel PCB rimane nella tabella dei processi finch√© il padre non esegue la chiamata wait().  
51. Qual √® lo scopo della Comunicazione tra Processi (IPC)?  
 * Risposta: Permettere ai processi di scambiare dati e sincronizzarsi. Utile per la condivisione di informazioni, la velocit√† di calcolo (parallelismo) e la modularit√†.  
52. Confronta i due modelli di IPC: Memoria Condivisa (Shared Memory) e Scambio di Messaggi (Message Passing).  
 * Risposta: La memoria condivisa √® pi√π veloce (velocit√† della RAM) ma richiede sincronizzazione manuale; lo scambio di messaggi √® pi√π facile da implementare (specialmente in sistemi distribuiti) ma ha l'overhead delle system call.  
53. Nello scambio di messaggi, qual √® la differenza tra comunicazione Diretta e Indiretta?  
 * Risposta: Nella Diretta, il mittente deve nominare esplicitamente il destinatario; nella Indiretta, i messaggi vengono inviati a "caselle postali" (mailboxes) o porte.  
54. Cosa si intende per comunicazione Sincrona (Blocking) e Asincrona (Non-blocking)?  
 * Risposta: Sincrona: il mittente/ricevente si blocca finch√© il messaggio non √® inviato/ricevuto. Asincrona: il mittente invia e prosegue; il ricevente ottiene un messaggio o un valore nullo senza fermarsi.  
55. Cos'√® il buffering nei sistemi di messaggistica (Capacit√† zero, limitata, illimitata)?  
 * Risposta: Zero: il mittente deve aspettare il ricevente (appuntamento); Limitata: coda di lunghezza n; Illimitata: il mittente non si blocca mai.  
56. Descrivi il concetto di Socket.  
 * Risposta: √à un punto di terminazione (endpoint) per la comunicazione tra due processi attraverso una rete, identificato da una coppia Indirizzo IP e Numero di Porta.  
57. Cosa sono le RPC (Remote Procedure Calls)?  
 * Risposta: Permettono a un programma di eseguire una procedura su un altro computer come se fosse una chiamata locale, utilizzando "stubs" per gestire i dettagli della rete.  
58. Cos'√® una Pipe ordinaria (anonima) e qual √® il suo limite principale?  
 * Risposta: Permette la comunicazione unidirezionale tra due processi correlati (padre-figlio). Il limite √® che non pu√≤ essere usata tra processi non correlati.  
59. Cosa sono le Named Pipes (FIFO)?  
 * Risposta: Pipe che appaiono come file nel file system; permettono la comunicazione bidirezionale tra processi qualsiasi, anche senza legami di parentela.  
60. Perch√© lo scheduling dei processi √® necessario?  
 * Risposta: Per massimizzare l'utilizzo della CPU (tenerla sempre occupata) e per garantire tempi di risposta rapidi agli utenti in un sistema multitasking.  
  
üìò Capitolo 4: Thread (Domande 61-80)  
61. Cos'√® un Thread e in cosa differisce da un processo?  
 * Risposta: Un thread (o processo leggero) √® l'unit√† base di utilizzo della CPU. Mentre un processo ha un proprio spazio di indirizzamento isolato, i thread dello stesso processo condividono il codice, i dati e le risorse del sistema operativo, ma hanno ciascuno il proprio Program Counter, i registri e lo stack.  
62. Quali sono i quattro vantaggi principali della programmazione multithread?  
 * Risposta: 1) Reattivit√† (l'applicazione continua a rispondere anche se una parte √® bloccata); 2) Condivisione delle risorse (pi√π facile e veloce della IPC); 3) Economia (creare thread costa meno che creare processi); 4) Scalabilit√† (sfrutta meglio le architetture multiprocessore).  
63. Cosa condividono tra loro i thread appartenenti allo stesso processo?  
 * Risposta: Condividono la sezione del codice (text), la sezione dei dati (variabili globali) e le risorse del sistema operativo (come i file aperti e i segnali).  
64. Qual √® la differenza tra Parallelismo e Concorrenza?  
 * Risposta: La concorrenza permette a pi√π task di fare progressi (anche su una sola CPU tramite time-sharing). Il parallelismo permette l'esecuzione simultanea di pi√π task (richiede pi√π processori o core).  
65. Descrivi il Parallelismo dei Dati (Data Parallelism).  
 * Risposta: Distribuisce sottoinsiemi dello stesso dato su pi√π core, eseguendo la stessa operazione su ogni core (es. sommare una matrice gigante).  
66. Descrivi il Parallelismo delle Mansioni (Task Parallelism).  
 * Risposta: Distribuisce thread diversi (mansioni diverse) su pi√π core, dove ogni thread opera sugli stessi dati o su dati differenti.  
67. Cosa sono i Thread Utente (User Threads)?  
 * Risposta: Sono thread gestiti da librerie a livello utente senza il supporto diretto del kernel. Il kernel vede solo il processo e non i singoli thread.  
68. Cosa sono i Thread Kernel (Kernel Threads)?  
 * Risposta: Sono thread supportati e gestiti direttamente dal sistema operativo. Il kernel esegue lo scheduling dei singoli thread invece che dei processi.  
69. Descrivi il modello Many-to-One.  
 * Risposta: Molti thread utente sono mappati su un unico thread kernel. Se un thread utente esegue una system call bloccante, l'intero processo si blocca. Non sfrutta il multicore.  
70. Descrivi il modello One-to-One.  
 * Risposta: Ogni thread utente ha un corrispondente thread kernel. Offre massima concorrenza, ma la creazione di troppi thread pu√≤ appesantire il sistema (overhead del kernel). √à il modello usato da Linux e Windows.  
71. Descrivi il modello Many-to-Many.  
 * Risposta: Molti thread utente vengono multiplexati su un numero uguale o minore di thread kernel. Combina i vantaggi degli altri due modelli senza i loro limiti estremi.  
72. Cos'√® una Libreria di Thread (Thread Library)?  
 * Risposta: Fornisce al programmatore un'API per la creazione e gestione dei thread. Esempi principali sono Pthreads (POSIX), Windows threads e Java threads.  
73. Spiega la differenza tra la creazione di thread asincrona e sincrona.  
 * Risposta: Asincrona: il padre crea il figlio e continua l'esecuzione. Sincrona (fork-join): il padre aspetta che tutti i figli terminino prima di riprendere.  
74. Cosa succede se un thread chiama la system call fork()?  
 * Risposta: Dipende dall'implementazione: alcune versioni duplicano tutti i thread del processo, altre duplicano solo il thread che ha chiamato la fork().  
75. Qual √® lo scopo della system call exec() in un ambiente multithread?  
 * Risposta: Se un thread chiama exec(), il nuovo programma sostituir√† l'intero processo, inclusi tutti gli altri thread esistenti.  
76. Cos'√® la Cancellazione del Thread (Thread Cancellation) e quali sono i due tipi?  
 * Risposta: √à il termine di un thread prima che sia completato. 1) Asincrona: termina il thread bersaglio immediatamente. 2) Differita (deferred): il thread bersaglio controlla periodicamente se deve terminare (punto di cancellazione).  
77. Cosa sono i Segnali (Signals) nei sistemi UNIX?  
 * Risposta: Sono notifiche inviate a un processo per comunicare che si √® verificato un evento specifico. Possono essere sincroni (errori di memoria) o asincroni (pressione di Ctrl+C).  
78. Cos'√® un Thread Pool e perch√© si usa?  
 * Risposta: √à un insieme di thread creati all'avvio che aspettano lavoro in una coda. Evita il costo continuo di creazione/distruzione dei thread e limita il numero massimo di thread attivi.  
79. Cosa sono i Thread-Specific Data (Dati specifici del thread)?  
 * Risposta: Dati che appartengono esclusivamente a un determinato thread (non condivisi), utili quando il programmatore non ha controllo sulla creazione del thread (es. in un pool).  
80. Cos'√® lo Scheduler Activations?  
 * Risposta: Un meccanismo di comunicazione tra il kernel e la libreria dei thread (tramite upcalls) per mantenere il numero corretto di thread kernel assegnati a un'applicazione.  
  
üìò Capitolo 5: Scheduling della CPU (Domande 81-100)  
81. Qual √® l'obiettivo principale del multiprogramming in relazione alla CPU?  
 * Risposta: Massimizzare l'utilizzo della CPU (CPU utilization). L'idea √® di avere sempre un processo in esecuzione per evitare che la CPU rimanga inattiva durante le operazioni di I/O degli altri processi.  
82. Cos'√® il ciclo "CPU-I/O Burst Cycle"?  
 * Risposta: L'esecuzione di un processo consiste in un'alternanza di raffiche di calcolo (CPU burst) e raffiche di attesa per l'input/output (I/O burst). Lo scheduling avviene quando termina un CPU burst.  
83. Spiega la differenza tra Scheduling Preemptive (con diritto di prelazione) e Non-preemptive.  
 * Risposta: Nel Non-preemptive, un processo tiene la CPU finch√© non la rilascia volontariamente o termina. Nel Preemptive, il sistema operativo pu√≤ interrompere un processo in esecuzione per assegnare la CPU a un altro (es. quando arriva un processo a priorit√† pi√π alta).  
84. Qual √® il ruolo del Dispatcher?  
 * Risposta: √à il modulo che assegna materialmente il controllo della CPU al processo selezionato dallo scheduler. Si occupa del context switch, del passaggio alla modalit√† utente e del salto all'indirizzo corretto del programma.  
85. Definisci la "Dispatch Latency".  
 * Risposta: √à il tempo impiegato dal dispatcher per fermare un processo e avviarne un altro. Deve essere il pi√π piccolo possibile.  
86. Quali sono i 5 criteri principali per valutare un algoritmo di scheduling?  
 * Risposta: 1) CPU Utilization (massimizzare); 2) Throughput (n. processi completati nell'unit√† di tempo); 3) Turnaround Time (tempo totale dalla sottomissione alla fine); 4) Waiting Time (tempo passato nella ready queue); 5) Response Time (tempo dalla richiesta alla prima risposta).  
87. Descrivi l'algoritmo FCFS (First-Come, First-Served) e il suo principale difetto.  
 * Risposta: I processi sono serviti nell'ordine di arrivo. Il difetto principale √® l'effetto convoglio (Convoy Effect): processi brevi devono aspettare dietro un processo molto lungo, aumentando il tempo medio di attesa.  
88. Come funziona l'algoritmo SJF (Shortest Job First)?  
 * Risposta: Assegna la CPU al processo che ha il prossimo CPU burst pi√π breve. √à l'algoritmo ottimale per minimizzare il tempo medio di attesa.  
89. Qual √® la difficolt√† principale nell'implementare SJF?  
 * Risposta: Non √® possibile conoscere in anticipo la durata del prossimo CPU burst. Si pu√≤ solo stimare usando una media esponenziale dei burst precedenti.  
90. Cos'√® lo Shortest-Remaining-Time-First (SRTF)?  
 * Risposta: √à la versione preemptive di SJF. Se arriva un nuovo processo con un burst residuo minore di quello corrente, la CPU viene riassegnata al nuovo arrivato.  
91. Descrivi lo Scheduling a Priorit√† e il problema della Starvation.  
 * Risposta: Ogni processo ha un numero (priorit√†). La CPU va al processo con priorit√† pi√π alta. La Starvation avviene quando processi a bassa priorit√† non vengono mai eseguiti perch√© arrivano sempre processi a priorit√† pi√π alta.  
92. Cos'√® la tecnica dell'"Aging" (Invecchiamento)?  
 * Risposta: √à la soluzione alla starvation: consiste nell'aumentare gradualmente la priorit√† dei processi che attendono nella ready queue da molto tempo.  
93. Come funziona l'algoritmo Round Robin (RR)?  
 * Risposta: √à progettato per i sistemi time-sharing. Ogni processo riceve una piccola unit√† di tempo di CPU (time quantum). Allo scadere, il processo viene messo in coda e la CPU passa al successivo.  
94. Come influisce la dimensione del Time Quantum sulle prestazioni del Round Robin?  
 * Risposta: Se il quantum √® troppo grande, RR diventa un FCFS. Se √® troppo piccolo, l'overhead del context switch diventa eccessivo, rallentando il sistema.  
95. Descrivi le Multilevel Queue (Code a pi√π livelli).  
 * Risposta: La ready queue √® divisa in code separate (es. processi interattivi in primo piano e processi batch in background). Ogni coda pu√≤ avere il suo algoritmo di scheduling specifico.  
96. Cosa differenzia le Multilevel Feedback Queues dalle code semplici?  
 * Risposta: Permettono ai processi di spostarsi tra le code. Se un processo usa troppa CPU viene spostato in una coda a priorit√† pi√π bassa; se un processo aspetta troppo viene promosso in una a priorit√† pi√π alta (aging).  
97. Cos'√® l'Affinit√† del Processore (Processor Affinity)?  
 * Risposta: Nei sistemi multiprocessore, √® la tendenza a mantenere un processo sulla stessa CPU per sfruttare i dati gi√† presenti nella memoria cache di quel processore.  
98. Spiega la differenza tra Load Balancing "Push" e "Pull".  
 * Risposta: Push migration: un task specifico controlla il carico e "spinge" processi dalle CPU cariche a quelle scariche. Pull migration: una CPU inattiva "tira" un processo da una coda di una CPU occupata.  
99. Cos'√® il Real-Time Scheduling "Hard" rispetto al "Soft"?  
 * Risposta: Nel Hard, i task devono assolutamente essere completati entro la loro deadline. Nel Soft, si garantisce solo la priorit√† ai task critici, ma senza garanzie assolute di scadenza.  
100. Definisci la Latenza di Interruzione (Interrupt Latency) nei sistemi Real-Time.  
 * Risposta: √à l'intervallo di tempo dal momento in cui arriva un'interruzione a quando inizia l'esecuzione della routine di servizio corrispondente. Deve essere minima per garantire la reattivit√† del sistema.  
  
üìò Capitolo 6: Sincronizzazione dei Processi (Domande 101-120)  
101. Cos'√® una Race Condition (Corsa critica)?  
 * Risposta: √à una situazione in cui pi√π processi accedono e manipolano dati condivisi in modo concorrente, e l'esito finale dell'esecuzione dipende dall'ordine particolare in cui avvengono gli accessi.  
102. Definisci il problema della Sezione Critica.  
 * Risposta: √à un segmento di codice in cui un processo modifica dati condivisi (variabili, tabelle, file). Il problema consiste nel progettare un protocollo che garantisca che nessun altro processo sia nella sua sezione critica mentre uno lo √® gi√†.  
103. Quali sono i tre requisiti fondamentali per una soluzione al problema della sezione critica?  
 * Risposta: 1) Mutua Esclusione (solo un processo alla volta); 2) Progresso (se nessuno √® nella sezione critica, la decisione su chi entra non pu√≤ essere rimandata all'infinito); 3) Attesa Limitata (un processo non deve aspettare per sempre l'ingresso).  
104. Spiega l'approccio dei "Kernel Preemptive" vs "Non-preemptive" per la sincronizzazione.  
 * Risposta: Un kernel non-preemptive evita race condition perch√© un processo non viene interrotto mentre √® in modalit√† kernel. Un kernel preemptive √® pi√π difficile da progettare ma pi√π reattivo, poich√© permette interruzioni anche durante le operazioni di sistema.  
105. Cos'√® la soluzione di Peterson?  
 * Risposta: √à una soluzione classica basata su software per due processi. Utilizza due variabili condivise: un array flag (intenzione di entrare) e una variabile turn (a chi tocca). √à limitata a due processi e richiede un'architettura di memoria specifica.  
106. Cosa si intende per supporto hardware alla sincronizzazione?  
 * Risposta: L'uso di istruzioni atomiche speciali fornite dalla CPU, come TestAndSet o CompareAndSwap, che permettono di leggere e modificare una variabile in un unico passo indivisibile.  
107. Cos'√® l'Atomicit√†?  
 * Risposta: Una propriet√† di un'operazione o di un insieme di istruzioni che garantisce che vengano eseguite come un'unica unit√† senza interruzioni. Se fallisce, non deve lasciare effetti parziali.  
108. Definisci il Mutex Lock.  
 * Risposta: √à lo strumento di sincronizzazione pi√π semplice. Un processo deve acquisire il lock (acquire()) prima di entrare nella sezione critica e rilasciarlo (release()) all'uscita. √à basato su una variabile booleana.  
109. Cos'√® lo Spinlock e quando √® utile usarlo?  
 * Risposta: √à un mutex lock in cui il processo "gira" in un ciclo continuo aspettando che il lock si liberi (busy waiting). √à utile in sistemi multiprocessore se il tempo di attesa previsto √® inferiore a quello di due context switch.  
110. Cos'√® un Semaforo e qual √® la sua struttura?  
 * Risposta: √à una variabile intera a cui si accede solo tramite due operazioni atomiche: wait() (o P) e signal() (o V). Se il valore √® \le 0, il processo chiamante si blocca.  
111. Differenza tra Semaforo Binario e Semaforo Counting.  
 * Risposta: Il binario (0 o 1) agisce come un mutex. Il counting pu√≤ assumere qualsiasi valore intero e viene usato per gestire l'accesso a una risorsa con pi√π istanze disponibili.  
112. Come si risolve il problema del "Busy Waiting" nei semafori?  
 * Risposta: Implementando una coda di attesa associata al semaforo. Invece di ciclare, il processo viene sospeso (stato waiting) e messo in una coda; viene poi risvegliato da un altro processo tramite l'operazione signal().  
113. Cos'√® l'Inversione di Priorit√† (Priority Inversion)?  
 * Risposta: Si verifica quando un processo ad alta priorit√† deve aspettare una risorsa detenuta da uno a bassa priorit√†, che a sua volta √® interrotto da uno a priorit√† media.  
114. Descrivi il protocollo di Ereditariet√† della Priorit√† (Priority Inheritance).  
 * Risposta: √à la soluzione all'inversione di priorit√†: il processo a bassa priorit√† che detiene il lock "eredita" temporaneamente la priorit√† alta del processo che lo sta aspettando, finch√© non rilascia la risorsa.  
115. Descrivi il problema del Produttore-Consumatore.  
 * Risposta: Un produttore inserisce dati in un buffer e un consumatore li preleva. La sincronizzazione deve impedire che il produttore inserisca in un buffer pieno o che il consumatore prelevi da un buffer vuoto.  
116. Descrivi il problema dei Lettori-Scrittori.  
 * Risposta: Pi√π lettori possono leggere contemporaneamente, ma se uno scrittore sta modificando il dato, nessun altro (lettore o scrittore) pu√≤ accedere. Esistono varianti che danno priorit√† ai lettori o agli scrittori.  
117. Descrivi il problema dei Cinque Filosofi.  
 * Risposta: Un problema classico che illustra i pericoli del deadlock e della starvation nell'allocazione di risorse multiple (bacchette) tra processi concorrenti.  
     
118. Cos'√® un Monitor?  
 * Risposta: √à un costrutto di sincronizzazione di alto livello (tipico di Java o C#) che incapsula dati e procedure, garantendo automaticamente che solo un thread alla volta possa eseguire una procedura al suo interno.  
119. A cosa servono le Variabili di Condizione (Condition Variables)?  
 * Risposta: Sono usate all'interno dei monitor per permettere a un thread di aspettare una condizione specifica (tramite wait()) e di essere risvegliato da un altro (tramite signal()).  
120. Qual √® la differenza tra la semantica "Signal and Wait" e "Signal and Continue" nei monitor?  
 * Risposta: In "Signal and Wait", chi segnala aspetta che chi √® stato risvegliato esca dal monitor. In "Signal and Continue", chi segnala continua la sua esecuzione e chi √® stato risvegliato deve aspettare che il monitor torni libero.  
  
üìò Capitolo 7: Deadlock (Domande 121-140)  
121. Qual √® la definizione formale di Deadlock?  
 * Risposta: Una situazione in cui ogni processo in un insieme di processi √® in attesa di un evento (tipicamente il rilascio di una risorsa) che pu√≤ essere causato solo da un altro processo appartenente allo stesso insieme.  
122. Quali sono le 4 condizioni necessarie affinch√© si verifichi un deadlock?  
 * Risposta: 1) Mutua Esclusione (risorse non condivisibili); 2) Possesso e Attesa (un processo tiene una risorsa e ne aspetta un'altra); 3) Assenza di Preemption (le risorse non possono essere sottratte forzatamente); 4) Attesa Circolare (esiste una catena di processi P_0 \to P_1 \to \dots \to P_n \to P_0).  
123. Cos'√® un Grafo di Allocazione delle Risorse (RAG)?  
 * Risposta: √à un grafo diretto dove i nodi sono processi (cerchi) e tipi di risorse (quadrati). Un arco P \to R indica una richiesta; un arco R \to P indica un'allocazione.  
     
124. Se un grafo di allocazione contiene un ciclo, c'√® sempre un deadlock?  
 * Risposta: Se ogni risorsa ha una sola istanza, un ciclo implica sempre un deadlock. Se ci sono pi√π istanze, il ciclo √® una condizione necessaria ma non sufficiente (potrebbe non esserci stallo).  
125. Quali sono i tre modi principali per gestire il Deadlock?  
 * Risposta: 1) Prevenzione o Evitamento (assicurarsi che il sistema non entri mai in deadlock); 2) Rilevamento e Ripristino (lasciare che accada, trovarlo e risolverlo); 3) Ignorare il problema (Algoritmo dello Struzzo, usato da molti SO moderni).  
126. Come si implementa la "Prevenzione" (Prevention) del deadlock?  
 * Risposta: Invalidando almeno una delle 4 condizioni necessarie (es. eliminando l'attesa circolare imponendo un ordine gerarchico alle risorse).  
127. Cos'√® la tecnica dell'Attesa Circolare eliminata tramite Ordinamento Gerarchico?  
 * Risposta: Si assegna un numero intero a ogni tipo di risorsa. Un processo pu√≤ richiedere risorse solo in ordine crescente. Questo impedisce matematicamente la formazione di cicli.  
128. Qual √® la differenza tra Prevenzione (Prevention) ed Evitamento (Avoidance)?  
 * Risposta: La prevenzione pone limiti rigidi su come richiedere risorse. L'evitamento analizza dinamicamente ogni richiesta e la concede solo se il sistema rimane in uno "Stato Sicuro".  
129. Definisci lo "Stato Sicuro" (Safe State).  
 * Risposta: Uno stato √® sicuro se esiste una sequenza di esecuzione (Safe Sequence) tale che ogni processo possa completare il suo lavoro usando le risorse correnti pi√π quelle rilasciate dai processi precedenti.  
130. Cos'√® l'Algoritmo del Banchiere?  
 * Risposta: √à un algoritmo di evitamento del deadlock per sistemi con risorse a istanze multiple. Prima di allocare, simula l'assegnazione e verifica se il sistema rimane in uno stato sicuro.  
131. Quali strutture dati servono per l'Algoritmo del Banchiere?  
 * Risposta: 1) Available (risorse libere); 2) Max (richiesta massima di ogni processo); 3) Allocation (risorse gi√† assegnate); 4) Need (Max - Allocation, risorse ancora necessarie).  
132. Cosa succede se una richiesta di risorse porta il sistema in uno "Stato Insicuro"?  
 * Risposta: La richiesta non viene concessa e il processo viene messo in attesa, anche se le risorse sono fisicamente disponibili in quel momento.  
133. Descrivi l'Algoritmo di Rilevamento per istanze singole (Wait-for Graph).  
 * Risposta: Si crea un grafo dove i nodi sono solo i processi. Un arco P_i \to P_j esiste se P_i aspetta una risorsa tenuta da P_j. Se c'√® un ciclo, c'√® un deadlock.  
134. Ogni quanto dovrebbe essere eseguito l'algoritmo di rilevamento?  
 * Risposta: Dipende dalla frequenza prevista dei deadlock e da quanti processi saranno influenzati. Eseguirlo a ogni richiesta √® costoso (overhead CPU).  
135. Quali sono le due opzioni per il Ripristino (Recovery) da un deadlock?  
 * Risposta: 1) Terminazione dei processi (uccidere uno o tutti i processi coinvolti); 2) Prelazione delle risorse (sottrarre risorse a un processo e darne a un altro).  
136. Quali sono i criteri per scegliere quale processo terminare in caso di stallo?  
 * Risposta: Priorit√† del processo, tempo di esecuzione gi√† effettuato, risorse utilizzate, risorse necessarie per finire e se il processo √® interattivo o batch.  
137. Cos'√® il "Rollback" nel recupero da deadlock?  
 * Risposta: Riportare un processo a uno stato precedente sicuro (checkpoint) e ricominciare l'esecuzione da l√¨, dopo avergli sottratto la risorsa contesa.  
138. Spiega il problema della Starvation nel recupero da deadlock.  
 * Risposta: Se si sceglie sempre lo stesso processo come "vittima" per la prelazione (perch√© √® il pi√π economico da interrompere), quel processo non finir√† mai. Occorre includere il numero di "vittimizzazioni" nel criterio di scelta.  
139. Perch√© i sistemi operativi moderni spesso usano l'Algoritmo dello Struzzo?  
 * Risposta: Perch√© il costo degli algoritmi di prevenzione/evitamento √® troppo alto rispetto alla rarit√† del deadlock nei sistemi desktop. Si preferisce far crashare il sistema una volta all'anno piuttosto che rallentarlo ogni secondo.  
140. Differenza tra Deadlock e Livelock.  
 * Risposta: Nel Deadlock i processi sono bloccati (waiting). Nel Livelock i processi continuano a cambiare stato (attivi) ma nessuno dei due fa progressi, come due persone che cercano di evitarsi in un corridoio spostandosi continuamente dallo stesso lato.  
  
üìò Capitolo 8: Memoria Principale (Domande 141-160)  
141. Perch√© √® necessaria la protezione della memoria in un sistema multiprogrammato?  
 * Risposta: Per evitare che un processo utente acceda alla memoria del kernel o di altri processi, garantendo la stabilit√† e la sicurezza del sistema.  
142. Come vengono utilizzati i registri "Base" e "Limite"?  
 * Risposta: Il registro Base contiene l'indirizzo fisico pi√π basso legale; il registro Limite specifica la dimensione del range. Ogni indirizzo generato dalla CPU viene controllato: deve essere \ge \text{Base} e < \text{Base} + \text{Limite}.  
143. Cos'√® la MMU (Memory Management Unit)?  
 * Risposta: √à un dispositivo hardware che trasforma in tempo reale gli indirizzi logici (virtuali) in indirizzi fisici.  
144. Spiega il concetto di "Spazio di Indirizzamento Logico".  
 * Risposta: √à l'insieme di tutti gli indirizzi generati da un programma durante l'esecuzione. Non corrispondono necessariamente a posizioni reali nella RAM.  
145. Cosa si intende per "Caricamento Dinamico" (Dynamic Loading)?  
 * Risposta: Una routine non viene caricata in memoria finch√© non viene chiamata. Questo permette di risparmiare RAM, caricando solo il codice effettivamente utilizzato.  
146. Cos'√® lo "Swapping" (Scambio)?  
 * Risposta: Una tecnica che permette di spostare temporaneamente un processo dalla memoria principale a un'area di memoria secondaria (backing store) per liberare RAM, e poi riportarlo indietro per continuare l'esecuzione.  
147. Qual √® il limite principale dello Swapping classico?  
 * Risposta: L'elevato tempo di trasferimento tra disco e RAM, che pu√≤ rendere il sistema molto lento se lo swapping avviene troppo frequentemente (thrashing).  
148. Descrivi l'allocazione a Partizioni Fissee.  
 * Risposta: La memoria √® divisa in sezioni di dimensione fissa. Ogni partizione pu√≤ ospitare un solo processo. √à semplice ma causa frammentazione interna.  
149. Descrivi l'allocazione a Partizioni Variabili.  
 * Risposta: Il sistema operativo mantiene una tabella delle parti di memoria occupate e libere. Quando un processo arriva, gli viene assegnato un blocco di memoria grande quanto serve. Causa frammentazione esterna.  
150. Cos'√® un "Hole" (Buco) nella gestione della memoria?  
 * Risposta: Un blocco di memoria libera. Nel tempo, la memoria diventa un insieme di processi e buchi di varie dimensioni.  
151. Spiega la frammentazione esterna nell'allocazione contigua.  
 * Risposta: Avviene quando la memoria libera totale √® sufficiente per un processo, ma √® divisa in molti piccoli fori non contigui.  
152. Cos'√® la frammentazione interna?  
 * Risposta: Memoria sprecata quando a un processo viene assegnata una porzione di memoria leggermente pi√π grande di quella richiesta (es. in partizioni fisse o pagine).  
153. Come aiuta la Paginazione a risolvere la frammentazione esterna?  
 * Risposta: Permette allo spazio di indirizzamento fisico di un processo di essere non contiguo, mappando pagine logiche in frame fisici ovunque siano disponibili.  
154. Qual √® la struttura della Page Table (Tabella delle Pagine)?  
 * Risposta: √à un array di voci (PTE - Page Table Entries) dove l'indice √® il numero di pagina e il valore contenuto √® il numero di frame fisico.  
155. Cos'√® l'Offset (d) nell'indirizzamento paginato?  
 * Risposta: Rappresenta lo spostamento all'interno della pagina. Combinato con l'indirizzo base del frame, determina l'indirizzo fisico esatto.  
156. Perch√© il TLB √® necessario nella paginazione?  
 * Risposta: Per ridurre l'overhead degli accessi alla memoria. Senza TLB, ogni lettura/scrittura richiederebbe due accessi alla RAM (uno per la tabella, uno per il dato).  
157. Cosa succede durante un "Context Switch" in un sistema paginato rispetto al TLB?  
 * Risposta: Il TLB deve essere svuotato (flushed) affinch√© il nuovo processo non usi le traduzioni del vecchio, oppure ogni entry del TLB deve avere un identificatore di processo (ASID).  
158. Descrivi la Paginazione Gerarchica.  
 * Risposta: Una tecnica in cui la tabella delle pagine stessa √® divisa in pagine. Serve a gestire spazi di indirizzamento molto grandi senza occupare memoria contigua eccessiva per la tabella.  
159. Cosa sono le Pagine Condivise (Shared Pages)?  
 * Risposta: Sono pagine di codice "read-only" che possono essere mappate negli spazi logici di pi√π processi contemporaneamente (es. le librerie di sistema).  
160. Cos'√® la Segmentazione?  
 * Risposta: Uno schema di gestione della memoria che asseconda la visione dell'utente: la memoria √® divisa in segmenti logici (es. segmento codice, segmento stack, segmento dati) invece che in pagine di dimensione fissa.  
  
üìò Capitolo 9: Memoria Virtuale (Domande 161-180)  
161. Cos'√® la Memoria Virtuale e qual √® il suo vantaggio principale?  
 * Risposta: √à una tecnica che permette l'esecuzione di processi che non sono completamente carichi in memoria fisica. Il vantaggio principale √® che lo spazio di indirizzamento logico pu√≤ essere molto pi√π grande della RAM fisica, permettendo una maggiore multiprogrammazione.  
162. Spiega il concetto di "Paginazione su Richiesta" (Demand Paging).  
 * Risposta: √à un sistema di paginazione in cui le pagine vengono caricate in RAM solo quando vengono effettivamente richieste durante l'esecuzione, riducendo l'I/O inutile e l'occupazione di memoria.  
163. Cosa succede durante un Page Fault (Errore di pagina)?  
 * Risposta: La CPU prova ad accedere a una pagina con bit di validit√† "invalido". L'hardware solleva un trap al SO, che deve: 1) Trovare la pagina su disco; 2) Trovare un frame libero; 3) Caricare la pagina; 4) Aggiornare la tabella delle pagine; 5) Riavviare l'istruzione interrotta.  
164. Cos'√® il "Pure Demand Paging"?  
 * Risposta: Un caso estremo in cui un processo viene avviato con zero pagine in RAM. Ogni singola istruzione iniziale causer√† un page fault finch√© le pagine necessarie non saranno caricate.  
165. Perch√© √® necessario il supporto hardware per la paginazione su richiesta?  
 * Risposta: Serve una tabella delle pagine con bit valido/invalido e un meccanismo hardware capace di riavviare un'istruzione esattamente dal punto in cui √® stata interrotta dal page fault.  
166. Definisci l'Effective Access Time (EAT) per la memoria virtuale.  
 * Risposta: √à il tempo medio di accesso che considera la probabilit√† p di un page fault. EAT = (1 - p) \times \text{accesso\_RAM} + p \times \text{tempo\_gestione\_page\_fault}. Dato che il tempo di accesso al disco √® enorme, anche un p piccolissimo rallenta drasticamente il sistema.  
167. Cos'√® la Sostituzione della Pagina (Page Replacement)?  
 * Risposta: Quando si verifica un page fault ma non ci sono frame liberi, il SO deve scegliere una pagina vittima in RAM, scriverla su disco (se modificata) e sostituirla con la pagina richiesta.  
168. A cosa serve il "Dirty Bit" (o Modify Bit)?  
 * Risposta: Indica se una pagina in RAM √® stata modificata rispetto alla sua copia su disco. Se il bit √® 0, la pagina vittima pu√≤ essere sovrascritta senza scrivere sul disco, dimezzando il tempo di sostituzione.  
169. Descrivi l'algoritmo di sostituzione FIFO e il suo difetto (Anomalia di Belady).  
 * Risposta: Sostituisce la pagina pi√π vecchia. L'anomalia di Belady √® il fenomeno per cui, in alcuni casi, aumentando il numero di frame fisici disponibili, il numero di page fault aumenta invece di diminuire.  
170. Qual √® l'Algoritmo Ottimale (OPT) di sostituzione?  
 * Risposta: Sostituisce la pagina che non sar√† usata per il periodo di tempo pi√π lungo in futuro. √à impossibile da implementare perch√© richiede la conoscenza del futuro, ma funge da benchmark.  
171. Spiega l'algoritmo LRU (Least Recently Used).  
 * Risposta: Sostituisce la pagina che non viene utilizzata da pi√π tempo. Si basa sul principio di localit√† temporale: se una pagina √® stata usata di recente, √® probabile che venga usata di nuovo.  
172. Quali sono i limiti dell'implementazione di LRU?  
 * Risposta: Richiede un supporto hardware costoso (contatori o stack per ogni accesso alla memoria). Spesso si usano algoritmi di approssimazione LRU (come l'algoritmo Second-Chance).  
173. Come funziona l'algoritmo della Seconda Occasione (Second-Chance/Clock)?  
 * Risposta: Usa un bit di riferimento. Se la pagina selezionata (FIFO) ha il bit a 1, le viene data una "seconda occasione" (bit azzerato) e si passa alla successiva. Se il bit √® 0, viene sostituita.  
174. Cos'√® l'Allocazione Fisofissa vs Allocazione Prioritaria dei frame?  
 * Risposta: L'allocazione fissa assegna un numero fisso di frame a ogni processo. L'allocazione prioritaria permette a un processo ad alta priorit√† di "rubare" frame a processi a bassa priorit√†.  
175. Definisci il fenomeno del Thrashing.  
 * Risposta: Una situazione in cui un processo passa pi√π tempo a paginare (fare I/O) che a eseguire calcoli. Accade quando un processo non ha abbastanza frame per contenere il suo "Working Set".  
176. Cos'√® il Modello del Working Set?  
 * Risposta: Si basa sul principio di localit√†. Il Working Set √® l'insieme delle pagine usate attivamente da un processo in un intervallo di tempo \Delta. Il SO deve garantire che la somma dei Working Set di tutti i processi sia \le RAM totale per evitare il thrashing.  
177. Cos'√® il File Mapping (Memory-Mapped Files)?  
 * Risposta: Permette di mappare un file su disco direttamente nello spazio di indirizzamento virtuale di un processo, trattando l'I/O del file come normali accessi alla memoria.  
178. Come viene gestita la memoria Kernel rispetto a quella utente?  
 * Risposta: Il kernel spesso richiede memoria contigua per l'hardware (DMA). Usa algoritmi specifici come il Buddy System o lo Slab Allocation per minimizzare la frammentazione interna ed esterna.  
179. Spiega il Buddy System.  
 * Risposta: Alloca memoria in potenze di 2. Se serve un blocco da 4KB e ne hai uno da 8KB, lo dividi in due "buddy" da 4KB. Quando vengono liberati, se entrambi sono liberi, si ricombinano in un blocco unico.  
180. Cos'√® la Slab Allocation?  
 * Risposta: Usa cache di oggetti pre-allocati (es. PCB, semafori) per evitare la frammentazione e velocizzare l'allocazione di strutture dati del kernel usate frequentemente.  
  
üìò Capitolo 10: Struttura della Memoria di Massa (Domande 181-200)  
181. Quali sono le tre componenti principali della latenza di un disco magnetico (HDD)?  
 * Risposta: 1) Seek time (tempo di posizionamento della testina sul cilindro); 2) Rotational latency (tempo affinch√© il settore desiderato ruoti sotto la testina); 3) Transfer time (tempo effettivo di spostamento dei dati).  
182. Perch√© √® necessario lo scheduling del disco (Disk Scheduling)?  
 * Risposta: Poich√© l'accesso al disco √® estremamente lento rispetto alla CPU, il SO deve ordinare le richieste di I/O per minimizzare il movimento totale della testina (seek time) e massimizzare il throughput.  
183. Descrivi l'algoritmo FCFS (First-Come, First-Served) per il disco.  
 * Risposta: Le richieste sono servite nell'ordine in cui arrivano. √à intrinsecamente equo ma non ottimizza affatto il movimento della testina, causando spostamenti selvaggi tra cilindri distanti.  
184. Come funziona l'algoritmo SSTF (Shortest Seek Time First)?  
 * Risposta: Seleziona la richiesta pi√π vicina alla posizione attuale della testina. Riduce drasticamente il movimento della testina rispetto a FCFS, ma pu√≤ causare starvation per le richieste lontane.  
185. Spiega l'algoritmo SCAN (o algoritmo dell'ascensore).  
 * Risposta: La testina si muove da un'estremit√† all'altra del disco servendo le richieste lungo il percorso, per poi invertire la direzione una volta arrivata in fondo.  
186. Qual √® la differenza tra SCAN e C-SCAN (Circular SCAN)?  
 * Risposta: In C-SCAN, quando la testina arriva alla fine, torna immediatamente all'inizio senza servire richieste durante il ritorno. Fornisce un tempo di attesa pi√π uniforme rispetto allo SCAN normale.  
187. Descrivi gli algoritmi LOOK e C-LOOK.  
 * Risposta: Sono versioni ottimizzate di SCAN e C-SCAN: la testina non arriva fino al bordo fisico del disco, ma inverte la marcia non appena ha servito l'ultima richiesta nella direzione corrente.  
188. Come deve scegliere il SO l'algoritmo di scheduling del disco?  
 * Risposta: Dipende dal carico: SSTF o LOOK sono buone scelte standard. SCAN/C-SCAN sono migliori per sistemi con carichi pesanti. Molti SO moderni usano scheduler specifici per gestire code separate (es. per letture prioritarie).  
189. Cos'√® la Formattazione a Basso Livello (Low-level formatting)?  
 * Risposta: √à la creazione dei settori fisici sul disco, ognuno con un'intestazione (header), un'area dati e un codice di correzione errori (ECC). Viene fatta in fabbrica.  
190. Cos'√® la Formattazione Logica e la creazione del File System?  
 * Risposta: Il SO crea le strutture dati del file system (come la FAT o l'Innode table) e divide il disco in partizioni.  
191. Cos'√® il Master Boot Record (MBR)?  
 * Risposta: √à il primo settore del disco che contiene il codice per avviare il SO e la tabella delle partizioni.  
192. Come vengono gestiti i "Bad Blocks" (settori danneggiati)?  
 * Risposta: Il controller del disco mantiene una lista di settori di riserva. Tramite il sector sparing, mappa un settore logico danneggiato su un settore fisico sano di riserva.  
193. Cos'√® lo Swap Space (Spazio di scambio) e dove risiede?  
 * Risposta: √à un'area del disco usata per estendere la RAM fisica. Pu√≤ risiedere in un file all'interno del file system o, pi√π efficientemente, in una partizione separata e dedicata.  
194. Definisci la struttura RAID (Redundant Array of Independent Disks).  
 * Risposta: Una tecnica che utilizza pi√π dischi in parallelo per aumentare l'affidabilit√† (tramite ridondanza) e le prestazioni (tramite parallelismo dei dati).  
195. Differenza tra RAID 0 (Striping) e RAID 1 (Mirroring).  
 * Risposta: RAID 0 divide i dati su pi√π dischi per la velocit√† ma non ha tolleranza ai guasti. RAID 1 duplica i dati su due dischi per la sicurezza (se uno muore, i dati sono nell'altro).  
196. Cos'√® il RAID 5 (Parit√† distribuita)?  
 * Risposta: I dati e le informazioni di parit√† sono distribuiti su tutti i dischi. Permette di perdere un disco senza perdere dati, con un costo in spazio inferiore rispetto al mirroring (RAID 1).  
197. Cos'√® il RAID 6 e perch√© √® pi√π sicuro del RAID 5?  
 * Risposta: Usa una doppia parit√† distribuita, permettendo al sistema di continuare a funzionare anche se falliscono due dischi contemporaneamente.  
198. Qual √® la differenza principale tra HDD e SSD (Solid State Drive) nello scheduling?  
 * Risposta: Gli SSD non hanno parti meccaniche (testine), quindi il "seek time" √® quasi nullo. Gli algoritmi come SCAN sono inutili; lo scheduling degli SSD si concentra sul bilanciamento dell'usura (wear leveling).  
199. Cos'√® il NAS (Network-Attached Storage)?  
 * Risposta: Un dispositivo di memoria di massa collegato a una rete anzich√© direttamente al computer, che fornisce accesso ai dati a livello di file.  
200. Cos'√® la SAN (Storage Area Network)?  
 * Risposta: Una rete dedicata ad alta velocit√† che collega server e dispositivi di storage, fornendo accesso ai dati a livello di blocchi (come se fossero dischi locali).  
  
üìò Capitolo 11: Interfaccia del File System (Domande 201-220)  
201. Cos'√® un File dal punto di vista del Sistema Operativo?  
 * Risposta: √à un'unit√† logica di memorizzazione, definita come un insieme di informazioni correlate registrate sulla memoria secondaria. √à un'astrazione dell'hardware.  
202. Quali sono gli attributi tipici di un file?  
 * Risposta: Nome, identificatore univoco (ID), tipo, posizione sul dispositivo, dimensione, protezione (permessi) e timestamp (creazione, modifica).  
203. Descrivi le operazioni base su un file.  
 * Risposta: Creazione, scrittura, lettura, riposizionamento (seek), cancellazione e troncamento.  
204. Perch√© √® necessaria l'operazione di "Open" (Apertura)?  
 * Risposta: Per evitare di cercare il file nella directory a ogni lettura/scrittura. L'apertura copia gli attributi del file in una tabella dei file aperti in RAM, restituendo un file descriptor (o handle).  
205. Qual √® la differenza tra la Tabella dei File Aperti del Sistema e quella del Processo?  
 * Risposta: Quella del processo contiene informazioni locali (es. il puntatore alla posizione corrente); quella del sistema contiene informazioni condivise (es. il numero di processi che hanno aperto quel file per gestirne la chiusura).  
206. Spiega la differenza tra Accesso Sequenziale e Accesso Diretto.  
 * Risposta: L'accesso sequenziale legge i dati nell'ordine in cui sono scritti (come un nastro). L'accesso diretto permette di saltare a un blocco qualsiasi (es. record n. 45) senza leggere i precedenti (tipico dei dischi).  
207. Cos'√® una Directory?  
 * Risposta: √à un "contenitore" che mappa i nomi dei file nelle loro voci corrispondenti (FCB - File Control Block). Pu√≤ essere vista come una tabella di simboli.  
208. Descrivi la struttura di directory a due livelli.  
 * Risposta: Ogni utente ha la propria directory (UFD) sotto una directory principale (MFD). Risolve i conflitti di nomi tra utenti diversi, ma non permette di organizzare i file in sottocartelle.  
209. Cos'√® la struttura di directory ad Albero (Tree-Structured Directory)?  
 * Risposta: √à la struttura moderna in cui una directory pu√≤ contenere file e altre sottodirectory, permettendo un'organizzazione gerarchica infinita.  
210. Qual √® la differenza tra un Cammino Assoluto (Absolute Path) e uno Relativo?  
 * Risposta: Il cammino assoluto inizia dalla radice (root, /); quello relativo inizia dalla directory corrente di lavoro (Working Directory).  
211. Cos'√® un Grafo Aciclico per le directory?  
 * Risposta: Una struttura che permette a directory o file di essere condivisi in pi√π punti (tramite link), ma vieta la creazione di cicli che manderebbero gli algoritmi di ricerca in loop infinito.  
212. Spiega la differenza tra Hard Link e Symbolic Link (Soft Link).  
 * Risposta: L'Hard Link √® un altro nome per lo stesso file fisico (stesso numero di inode). Il Symbolic Link √® un file speciale che contiene il percorso di un altro file.  
213. Cos'√® il "Mounting" di un File System?  
 * Risposta: L'operazione con cui un file system esterno viene collegato a un punto specifico (Mount Point) dell'albero delle directory principale, rendendolo accessibile.  
214. Quali sono i metodi principali di condivisione dei file tra utenti?  
 * Risposta: Tramite permessi di accesso (Read, Write, Execute) e tramite ID di utente (UID) e di gruppo (GID) per identificare i proprietari.  
215. Cos'√® un File Control Block (FCB)?  
 * Risposta: Una struttura dati (chiamata inode in UNIX) che contiene tutte le informazioni su un file tranne il suo nome (permessi, proprietario, puntatori ai blocchi di dati).  
216. Come vengono gestiti i permessi di accesso in UNIX (rwx)?  
 * Risposta: Vengono assegnati tre bit (leggi, scrivi, esegui) per tre categorie: Proprietario (Owner), Gruppo (Group) e Altri (Public).  
217. Cos'√® la Consistenza del File System?  
 * Risposta: Uno stato in cui le strutture dati sul disco (es. bit map dei blocchi liberi) corrispondono alla realt√† dei file salvati. In caso di crash, il sistema usa tool come fsck o il Journaling per ripristinarla.  
218. Spiega il concetto di Journaling.  
 * Risposta: Il SO scrive ogni modifica programmata in un file di log (journal) prima di eseguirla. Se il sistema crasha, pu√≤ rileggere il log e completare o annullare l'operazione in sospeso.  
219. Cos'√® il VFS (Virtual File System)?  
 * Risposta: Uno strato del kernel che fornisce un'interfaccia unica per accedere a file system diversi (es. NTFS, ext4, NFS) senza che l'utente o i programmi debbano conoscerne le differenze.  
220. Cos'√® il Remote File System (NFS)?  
 * Risposta: Un protocollo che permette a un computer di accedere ai file di un altro computer attraverso la rete come se fossero locali, usando l'architettura Client-Server.  
  
üìò Capitolo 13: Sistemi di I/O (Domande 221-240)  
221. Cos'√® il "Bus" e qual √® la differenza tra bus di sistema e bus di espansione?  
 * Risposta: Il bus √® un insieme di fili e un protocollo che permette il passaggio di segnali tra componenti. Il bus di sistema collega CPU e RAM; il bus di espansione (es. PCIe) collega i dispositivi di I/O (schede video, dischi).  
222. Cosa sono i Registri del Controller (Porte di I/O)?  
 * Risposta: Ogni dispositivo √® gestito da un controller che comunica con la CPU tramite quattro registri: Data-in (lettura), Data-out (scrittura), Status (stato del dispositivo) e Control (comandi).  
223. Spiega la differenza tra I/O tramite porte e Memory-Mapped I/O.  
 * Risposta: Nell'I/O tramite porte, la CPU usa istruzioni speciali (es. in, out). Nel Memory-Mapped I/O, i registri del controller sono mappati in indirizzi di memoria: la CPU scrive/legge in RAM per comandare l'hardware.  
224. Cos'√® il Polling (Busy Waiting) e quando √® inefficiente?  
 * Risposta: √à la tecnica in cui la CPU legge ripetutamente il registro di Status finch√© il dispositivo non √® pronto. √à inefficiente se il dispositivo √® lento, perch√© spreca cicli di CPU in un ciclo inutile.  
225. Descrivi il meccanismo degli Interrupt (Interruzioni) nell'I/O.  
 * Risposta: Il dispositivo invia un segnale hardware alla CPU quando ha finito un compito. La CPU sospende il processo corrente, esegue l'Interrupt Handler e poi riprende il lavoro. Evita il polling.  
226. Cos'√® il Controller delle Interruzioni (APIC)?  
 * Risposta: Un componente hardware che gestisce le priorit√† delle interruzioni, decidendo quale segnalare alla CPU se ne arrivano pi√π contemporaneamente.  
227. Spiega il Direct Memory Access (DMA).  
 * Risposta: √à un controller speciale che gestisce il trasferimento di dati tra memoria e dispositivo senza l'intervento della CPU per ogni byte. La CPU interviene solo all'inizio e alla fine del trasferimento.  
228. Qual √® la differenza tra un'interfaccia a blocchi e una a caratteri?  
 * Risposta: I dispositivi a blocchi (es. HDD/SSD) leggono/scrivono unit√† di dimensione fissa e permettono l'accesso diretto. I dispositivi a caratteri (es. tastiera/mouse) gestiscono un flusso di singoli byte in ordine sequenziale.  
229. Cos'√® il Blocking I/O (I/O bloccante)?  
 * Risposta: Quando un processo chiede un I/O, la sua esecuzione viene sospesa (stato Waiting) finch√© l'operazione non √® completata. √à il metodo pi√π semplice per il programmatore.  
230. Cos'√® il Non-blocking I/O?  
 * Risposta: La chiamata di I/O restituisce immediatamente il controllo al processo con un valore che indica se l'operazione √® pronta o meno. Il processo continua a girare.  
231. Spiega l'Asynchronous I/O (I/O asincrono).  
 * Risposta: Il processo richiede l'I/O e continua l'esecuzione. Il SO notificher√† il processo (tramite segnale o callback) solo quando l'intera operazione sar√† conclusa.  
232. Cos'√® il Buffering e perch√© si usa?  
 * Risposta: √à l'uso di un'area di memoria per memorizzare dati durante il trasferimento. Serve a gestire differenze di velocit√† tra dispositivi, differenze di dimensione dei dati e a supportare la semantica di "copia" dei dati.  
233. Cos'√® il Caching nel sistema di I/O?  
 * Risposta: Mantenere una copia dei dati in una memoria veloce per accelerare gli accessi futuri (es. mantenere in RAM i settori del disco letti spesso).  
234. Cos'√® lo Spooling (Simultaneous Peripheral Operations On-Line)?  
 * Risposta: Un buffer usato per dispositivi che non possono gestire flussi di dati interlacciati (es. la stampante). I dati dei vari processi vengono accumulati su disco e inviati uno alla volta al dispositivo.  
235. Qual √® il ruolo del Device Driver?  
 * Risposta: √à lo strato software specifico per un hardware che "traduce" le chiamate generiche del kernel (es. read()) in comandi specifici per quel controller.  
236. Cos'√® il sottosistema di I/O del Kernel?  
 * Risposta: √à la parte del kernel che fornisce servizi comuni a tutti i driver: scheduling dell'I/O, buffering, caching, spooling, protezione e gestione degli errori.  
237. Spiega la gestione degli errori nell'I/O.  
 * Risposta: Il SO deve gestire fallimenti hardware (es. disco pieno o non leggibile) restituendo codici d'errore o tentando di ripetere l'operazione se il problema √® transitorio.  
238. Cos'√® la "I/O Protection"?  
 * Risposta: Tutte le istruzioni di I/O sono istruzioni privilegiate. Un utente non pu√≤ accedere direttamente all'hardware, ma deve passare attraverso system call affinch√© il SO possa controllare i permessi.  
239. Cos'√® il concetto di "Double Buffering"?  
 * Risposta: L'uso di due buffer: mentre il dispositivo riempie uno, la CPU elabora l'altro. Migliora le prestazioni parallelizzando I/O ed elaborazione.  
240. Descrivi la "I/O Request Packet" (IRP) in sistemi come Windows.  
 * Risposta: Una struttura dati che rappresenta una richiesta di I/O che attraversa i vari strati del kernel (dal file system al driver fisico) portando con s√© parametri e stato.  
  
üìò Capitolo 14: Protezione (Domande 241-260)  
241. Qual √® la differenza tra Protezione e Sicurezza?  
 * Risposta: La Protezione riguarda i meccanismi interni per controllare l'accesso alle risorse da parte di processi e utenti. La Sicurezza riguarda la difesa del sistema da minacce esterne (virus, hacker) e interne (furto di dati).  
242. Cos'√® il "Principio del Privilegio Minimo" (Least Privilege)?  
 * Risposta: Gli utenti e i processi devono operare con il set minimo di privilegi necessari per completare il proprio compito, limitando i danni in caso di errore o compromissione.  
243. Cos'√® un Dominio di Protezione (Protection Domain)?  
 * Risposta: √à una collezione di coppie (oggetto, diritti-di-accesso). Definisce cosa un processo pu√≤ fare su quali risorse in un dato momento.  
244. Spiega il concetto di Matrice di Accesso (Access Matrix).  
 * Risposta: √à un modello astratto dove le righe sono i domini, le colonne sono gli oggetti e le celle contengono i diritti (es. read, write).  
245. Cos'√® una Access Control List (ACL)?  
 * Risposta: √à un'implementazione della matrice per colonne: ogni oggetto ha una lista di domini e i relativi permessi. √à usata comunemente nei file system (es. Windows NTFS).  
246. Cos'√® una Capability List (C-List)?  
 * Risposta: √à un'implementazione della matrice per righe: ogni processo possiede una lista di "biglietti" (capability) che gli danno diritto ad accedere a determinati oggetti.  
247. Cos'√® il "Role-Based Access Control" (RBAC)?  
 * Risposta: I privilegi sono assegnati a ruoli (es. "Amministratore", "Studente") e gli utenti vengono assegnati ai ruoli. Semplifica la gestione in sistemi grandi.  
248. Spiega la differenza tra Revoca Immediata e Revoca Differita dei diritti.  
 * Risposta: La revoca immediata cancella il diritto istantaneamente (facile con le ACL, difficile con le Capability); quella differita avviene dopo un certo tempo o al verificarsi di un evento.  
249. Cos'√® il meccanismo dei "Password-based Capabilities"?  
 * Risposta: Un approccio ibrido dove l'accesso a un oggetto √® garantito dal possesso di una chiave crittografica o una password specifica.  
250. Descrivi la protezione basata su anelli (Protection Rings).  
 * Risposta: L'hardware divide i privilegi in cerchi concentrici. L'anello 0 (Kernel) ha pieni poteri, l'anello 3 (User) ha poteri minimi. Il passaggio avviene tramite "gate" controllati.  
üíÄ Le 10 Domande "Killer" (Integrazione Totale)  
Queste domande richiedono di collegare pi√π capitoli. Se rispondi bene a queste, hai il 30 in tasca.  
K1. Collega la Paginazione alla Protezione: come fa l'hardware a impedire che un processo acceda alla memoria di un altro?  
 * Risposta: Ogni processo ha la sua Page Table privata gestita dal kernel. Poich√© la CPU usa solo la tabella del processo corrente (puntata dal PTBR), √® fisicamente impossibile per un processo generare un indirizzo che punti a un frame di un altro processo, a meno che non siano Shared Pages esplicitamente configurate dal SO.  
K2. Come interagisce lo Scheduling della CPU con il Context Switch?  
 * Risposta: Lo scheduler sceglie il prossimo processo, ma il Dispatcher esegue materialmente il context switch salvando il PCB del vecchio e caricando quello del nuovo. Se la frequenza di scheduling √® troppo alta, l'overhead del context switch degrada le prestazioni totali.  
K3. Perch√© il DMA pu√≤ essere un problema per la coerenza della Cache?  
 * Risposta: Poich√© il DMA scrive direttamente in RAM senza passare dalla CPU, i dati presenti nella Cache della CPU potrebbero risultare obsoleti (stale data). Il sistema deve invalidare la cache o usare protocolli di "cache snooping".  
K4. Qual √® il legame tra Interrupt e System Call?  
 * Risposta: Una System Call viene spesso implementata come un'interruzione software o Trap. Quando il programma chiama una funzione del kernel, l'hardware solleva una trap, cambia il Mode Bit a 0 (Kernel) e salta alla routine di servizio corrispondente nel vettore delle interruzioni.  
K5. Come pu√≤ un Deadlock influenzare la gestione della memoria?  
 * Risposta: In sistemi con Swapping, se tutti i processi sono in stallo (deadlock) aspettando risorse I/O, nessuno rilascia memoria RAM. Il sistema potrebbe andare in Thrashing o bloccarsi completamente perch√© non c'√® memoria libera per far avanzare nessun processo "vittima".  
K6. In che modo la Paginazione Gerarchica aiuta a gestire il "File Mapping"?  
 * Risposta: Permette di mappare file enormi nello spazio virtuale senza caricare tutto il file in RAM. Solo le tabelle delle pagine interne necessarie vengono create quando si accede a una parte specifica del file (Demand Paging).  
K7. Descrivi il percorso di un dato dal Disco alla RAM durante un Page Fault.  
 * Risposta: 1. Trap (Page Fault). 2. Il kernel sospende il processo. 3. Lo Scheduler del Disco ordina la lettura. 4. Il DMA trasferisce il blocco dal disco alla RAM. 5. Un Interrupt segnala la fine dell'I/O. 6. La Page Table viene aggiornata. 7. Il processo torna in Ready Queue.  
K8. Perch√© i Semafori necessitano di istruzioni atomiche (es. TestAndSet) per essere implementati?  
 * Risposta: Perch√© le operazioni wait() e signal() modificano una variabile condivisa. Se non fossero atomiche, due processi potrebbero eseguire wait() contemporaneamente causando una Race Condition sul valore del semaforo stesso, rendendo nulla la sincronizzazione.  
K9. Come influisce l'Hit Ratio del TLB sulla velocit√† di un sistema a 2 o pi√π livelli di paginazione?  
 * Risposta: In un sistema a 2 livelli, un miss costa 3 accessi alla RAM. Con un Hit Ratio alto, la maggior parte degli accessi avviene a velocit√† cache (hardware), rendendo trascurabile il costo della gerarchia delle tabelle. Se l'Hit Ratio crolla, il sistema rallenta del 300%.  
K10. Perch√© il Journaling nel File System √® considerato una protezione contro i crash?  
 * Risposta: Perch√© garantisce l'atomicit√† delle operazioni sul file system. Scrivendo prima l'intenzione nel log, il SO pu√≤ ripristinare la consistenza delle strutture dati (come i bit di allocazione dei blocchi) anche se l'alimentazione viene interrotta a met√† di una scrittura.  
